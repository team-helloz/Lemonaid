# 하둡 에코시스템 실습

##### skeleton 프로젝트 구조

- src/main/java/ssafy/~~.java
    - MapReduce 알고리즘 코드 및 드라이버
- prepare_~~~.sh
    - docker hadoop에서 실행할 shell 코드
- remote_~~~.sh
    - 하둡 클러스터 서버에서 실행할 shell 코드

##### 예제 1. 로컬 + 하둡(클러스터 서버)

1. 데이터 파일은 하둡 클러스터 서버의 hdfs에 저장
    - 테스트 파일은 csv로 작성되어있음
    
    ```
    ml/input/ratings.csv
    
    ......
    2797,2176,4.5,1112205675
    2797,2329,5.0,1112205186
    2797,2467,3.5,1112215683
    2797,2677,4.0,1112216052
    2797,2716,1.0,1112209392
    2797,2750,4.5,1112205721
    2797,2858,1.5,1112208073
    ......
    ```
    
2. 로컬에서 소스코드(java)를 작성
3. 소스코드 빌드 후 jar 파일을 하둡 클러스터 서버에 업로드
    
    ```bash
    # 소스 빌드
    ./mvnw clean package
    
    # 하둡 클러스터 서버에 jar 업로드
    scp -i ../hadoop.pem target/ssafy-*.jar $1:~/ssafy.jar
    ```
    
4. 맵리듀스 실행 후 결과 조회

##### 예제 2. 로컬 + 하둡(docker)

하둡(docker)에서 로컬 파일에 접근, 실행
클러스터 서버에서 실행한 과정과 동일하게 작동한다.

###### - 이하는 제공된 Docker Container 에서 진행

##### 예제 3. Spark

Scala 활용

1. hdfs에 Spark에서 읽을 파일을 저장
    
    ```bash
    $ hdfs dfs -put $SPARK_HOME/README.md
    ```
    
2. Scala에서 textFile 변수에 파일 할당
    
    ```scala
    $ spark-shell
    
    val textFile = spark.read.textFile("README.md")
    ```
    
3. wordCount 로직 실행
    
    ```scala
    val wordCounts = textFile.flatMap(line => line.split(" ")).groupByKey(identity).count()
    ```
    
4. collect로 출력
    
    ```scala
    wordCounts.collect()
    ```
    

##### 예제 4. 제플린 노트북에서 Spark SQL (PySpark)로 분석

pyspark에서 hdfs에 접근하여 Spark DataFrame을 생성하여 시각화할 수 있다.
TempTable로 테이블을 생성하여 sql로 접근하게 만들 수 있다.

※ 접근 주소
hadoop - localhost:8088
Zeppelin - localhost:9995
Spark - localhost:14040

##### 예제 5. Hive

1. 쿼리를 실행하기 위한 도구 비라인에 접속
    
    ```bash
    ~/skeleton-hadoop-maven$ beeline -n hadoop -u jdbc:hive2://localhost:10000
    ```
    
2. 테이블 생성
    
    ```bash
    0: jdbc:hive2://localhost:10000> CREATE TABLE user_ratings (
    	~~~
    );
    ```
    
3. 테이블 조회
    
    ```bash
    0: jdbc:hive2://localhost:10000> show tables;
    ...
    +---------------+
    |   tab_name    |
    +---------------+
    | user_ratings  |
    +---------------+
    1 row selected (0.257 seconds)
    ```
    
4. Hive에서 사용 가능하도록 HDFS에 저장
    
    ```bash
    0: jdbc:hive2://localhost:10000> LOAD DATA LOCAL INPATH '/home/hadoop/ml-25m/ratings.csv' OVERWRITE INTO TABLE user_ratings;
    ```
    
5. 맵리듀스(Hive에서 내부적으로 구현된 것 작동)와 함께 조회
    
    ```bash
    0: jdbc:hive2://localhost:10000> SELECT COUNT(*) FROM user_ratings;
    ...
    INFO  : Job running in-process (local Hadoop)
    INFO  : 2021-09-26 10:15:36,026 Stage-1 map = 100%,  reduce = 100%
    INFO  : Ended Job = job_local193815146_0002
    ...
    +-----------+
    |    _c0    |
    +-----------+
    | 25000095  |
    +-----------+
    1 row selected (6.858 seconds)
    ```
    

기타 SQL 쿼리를 사용하여 테이블 참조 가능.
이후로는 내부적으로 최적화가 이루어져 상대적으로 빠르게 작동한다.

Error List

전달받은 pem 파일의 권한 설정
[윈도우10에서 SSH 접속 시 pem 파일 권한변경](https://dabid.tistory.com/entry/%EC%9C%88%EB%8F%84%EC%9A%B010%EC%97%90%EC%84%9C-SSH-%EC%A0%91%EC%86%8D-%EC%8B%9C-pem-%ED%8C%8C%EC%9D%BC-%EA%B6%8C%ED%95%9C%EB%B3%80%EA%B2%BD)